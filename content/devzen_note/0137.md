---
title: "Notes for episode-0137"
date: 2017-04-09
draft: false
---

# Kubernetes-1.6
http://blog.kubernetes.io/2017/03/kubernetes-1.6-multi-user-multi-workloads-at-scale.html

- Focus: scale + automation. 5K nodes cluster is supported (150K pods)
- etcd v3
- Federation for more nodes & multi-cluster (kubefed - becomes beta)
- RBAC is beta (is used by default). Allows to give users/service accounts access to specific resourses on a per-namespace basis
- kubeadm tool - is beta (create a secure cluster, RBAC is supported)
- Node affinity/anti-affinity is in beta (assign to nodes based on node labels).
- Taints and tolerations is in beta (exclude pods from particular nodes).
- Pod affinity and anti-affinity is in beta (hard and soft requirements for spreading and packing pods relative to one another within arbitrary topologies).
- Multiple schedulers in beta
- StorageClass is stable (aws, azure, gcp, openstack, vmware vsphere)
- Dynamic volume provisioning is stable (create / delete storage on demand, no need to pre-provision)
- information in pod at creation time (including secrets, volumes, volume mounts, env vars https://kubernetes.io/docs/user-guide/pod-preset/


# Chronix: Long term storage and retrieval technology for anomaly detection in operational data
https://blog.acolyer.org/2017/03/10/chronix-long-term-storage-and-retrieval-technology-for-anomaly-detection-in-operational-data/

- time series DB optimized to support anomaly detection
- схема  “Date-Delta-Compaction” (DDC) + компрессия.
- Это позволяет сократить 20-68% storage space, 80-92% data retrieval time, 73-97% runtime of analyzing functions
- Time series requirements for anomaly detection (Chronix supports all!):
    - generic data model that allows exploratory analysis
    - built-in analysis functions (+ complex ones: sax, dynamic time warping)
    - time and space efficient lossless storage
- Chronix хранит упорядоченные блоки информации (ts + value pair) для произвольных типов в blobs. Тип информации - влияет на список доступных функций для обработки. Каждый блоб (“запись”) - хранит также ts начала и конца + мета-информацию о записи (включая атрибуты, заданные пользователем)
- functional-lossless storage (можно потерять данные, которые не влияют на предсказательную способность)
- Pipeline (для импорта - сверху вниз, для query - снизу вверх)
    - optional transformation
    - Группировка по блокам + формирование аттрибутов
    - Компрессия блоков
    - Сохранение
- Компрессия:
    - Значения компрессуются, т.к. чаще всего изменения между соседними точками очень маленькое
    - Ts (timestamp) тоже компрессируются
    - Затем получившиеся бинарные данные можно сжать стандартными bzip2/gzip/lz4/snappy/xz
    - Первые две - более простые вариации того, что у Facebook есть в Gorilla (open source: Beringei https://github.com/facebookincubator/beringei)
- Chronix выбросит ts если он почти точно может их воспроизвести (с точностью до указанного процента). Он также хранит накапливаемую ошибку и может в дальнейшем использовать (если она будет слишком большой)
- Установка и конфигурация - три значения: DDC threshold (for ts), chunk size, compression algorithm. DDC threshold: график inacuracy rates vs threshold. Default DDC threshold is 200ms
- Chunk size and compression - in tandem. First: minimal chunk size (plot vs compression rate). Then: chunksize vs compression alg (plot vs access time im ms)
- Сравнение с InfluxDB, OpenTSB, KairosDB. 108GB (2 real world apps). Chronix needs 8.7GB,  чтобы хранить 108.2GB. Для базовых функций проигрывает InfluxDB, но для более сложных - значительный выигрыш
- С графитом не сравнивали, т.к. авторы не считают его подходящим для долгосрочного хранения

# DigitalOcean Introduce Monitoring
https://www.digitalocean.com/company/blog/introducing-monitoring/

- Free for all droplets
- Alert when problem occurs
- Продолжение системы open-source агента, который рассказывал про здоровье каждого дроплета
- 1m- интервалы
- хранится за месяц
- CPU, Disk I/O, Memory, Disk Usage, Bandwidth, process list  (ordered by CPU)
- Alert Policy (CPU - is above - 70 - 5min)
- Alerts -> Slack, Email
- Next: API, monitor block storage,

# Baidu launches SwiftScribe (transcribes audio with AI)
https://venturebeat.com/2017/03/13/baidu-launches-swiftscribe-an-app-that-transcribes-audio-with-ai/

- Several years working on Speech Recognition software
- DeepSpeech, TalkType (Android keyboard),
- hour - 20min to subscribe. Change (capitalizing, punctuation, change spelling of cerain words)

# Data Stacks у гигантов: Facebook, Netflix, Airbnb, Pinterest
https://blog.keen.io/architecture-of-giants-data-stacks-at-facebook-netflix-airbnb-and-pinterest-9b7cd881af54

- Netflix:
    - 1.3PB per day, at peaks: 8M events per sec. 100 data engineers
    - Kafka, Elastic Search, S3, Spark, Hadoop
- Facebook:
    - 1B active users, largest warehouse.
    - Presto (distributed SQL query engine for ad-hoc analysis)
    - Data stores: Hive, HBase, Scribe
- Airbnb:
    - 100M users browsing, 2M listings
    - data team: 30+ engineers,
    - Hive, Spark, expanded Presto
- Pinterest
    - 10B+ pageviews per month, data team ~ 250 engineers
    - Kafka, Storm, Hadoop, HBase, Redshift
- Twitter/Crashlytics
    - Kafka, Storm, S3, Hadoop, Cassandra
- Статья - просто набор ссылок + пиар, смысла читать - нет


